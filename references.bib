@inproceedings{child2019generating,
  title={Generating Long Sequences with Sparse Transformers},
  author={Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  year={2019}
}

@article{beltagy2020longformer,
  title={Longformer: The Long-Document Transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={arXiv preprint arXiv:2004.05150},
  year={2020}
}

@article{wang2020linformer,
  title={Linformer: Self-Attention with Linear Complexity},
  author={Wang, Sinong and Li, Belinda Z and Khabsa, Madian and Fang, Han and Ma, Hao},
  journal={arXiv preprint arXiv:2006.04768},
  year={2020}
}

@article{katharopoulos2020transformers,
  title={Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention},
  author={Katharopoulos, Angelos and Vyas, Apoorv and Pappas, Nikolaos and Fleuret, François},
  journal={International Conference on Machine Learning},
  year={2020}
}

@article{choromanski2021rethinking,
  title={Rethinking Attention with Performers},
  author={Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and others},
  journal={International Conference on Learning Representations},
  year={2021}
}

@article{lee2021fnet,
  title={FNet: Mixing Tokens with Fourier Transforms},
  author={Lee-Thorp, James and Ainslie, Joshua and Eckstein, Ilya and Ontanon, Santiago},
  journal={arXiv preprint arXiv:2105.03824},
  year={2021}
}

@article{lan2019albert,
  title={ALBERT: A Lite BERT for Self-supervised Learning of Language Representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal={International Conference on Learning Representations},
  year={2020}
}

@article{press2017using,
  title={Using the Output Embedding to Improve Language Models},
  author={Press, Ofir and Wolf, Lior},
  journal={Proceedings of the 15th Conference of the European Chapter of the Association for Computational Linguistics},
  year={2017}
}

@article{shu2017compressing,
  title={Compressing Word Embeddings via Deep Compositional Code Learning},
  author={Shu, Raphael and Nakayama, Hideki},
  journal={International Conference on Learning Representations},
  year={2018}
}

@article{zoph2017neural,
  title={Neural Architecture Search with Reinforcement Learning},
  author={Zoph, Barret and Le, Quoc V},
  journal={International Conference on Learning Representations},
  year={2017}
}

@article{real2019regularized,
  title={Regularized Evolution for Image Classifier Architecture Search},
  author={Real, Esteban and Aggarwal, Alok and Huang, Yanping and Le, Quoc V},
  journal={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={4780--4789},
  year={2019}
}

@article{liu2019darts,
  title={DARTS: Differentiable Architecture Search},
  author={Liu, Hanxiao and Simonyan, Karen and Yang, Yiming},
  journal={International Conference on Learning Representations},
  year={2019}
}

@article{vaswani2017attention,
  title={Attention is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems},
  pages={5998--6008},
  year={2017}
}

@article{brown2020language,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{chowdhery2022palm,
  title={PaLM: Scaling Language Modeling with Pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{touvron2023llama,
  title={LLaMA: Open and Efficient Foundation Language Models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timothée and Rozière, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}

@article{mallat1989theory,
  title={A Theory for Multiresolution Signal Decomposition: The Wavelet Representation},
  author={Mallat, Stephane G},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={11},
  number={7},
  pages={674--693},
  year={1989}
}

@article{mallat2008wavelet,
  title={A Wavelet Tour of Signal Processing: The Sparse Way},
  author={Mallat, Stéphane},
  journal={Academic Press},
  year={2008}
}

@article{bracewell1986fourier,
  title={The Fourier Transform and Its Applications},
  author={Bracewell, Ronald N},
  journal={McGraw-Hill},
  year={1986}
}

@article{tolstikhin2021mlp,
  title={MLP-Mixer: An All-MLP Architecture for Vision},
  author={Tolstikhin, Ilya and Houlsby, Neil and Kolesnikov, Alexander and Beyer, Lucas and Zhai, Xiaohua and Unterthiner, Thomas and Yung, Jessica and Steiner, Andreas and Keysers, Daniel and Uszkoreit, Jakob and others},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
} 